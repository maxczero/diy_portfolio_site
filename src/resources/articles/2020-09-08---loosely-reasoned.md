---
title: Loosely Reasoned
date: "2020-09-08T22:40:32.169Z"
template: "post"
draft: false
slug: "loosely-reasoned"
category: "Music"
description: "A Brief Survey of AI in Film Scoring"
---

Machine learning models are becoming an increasingly popular problem-solving technique in data and computer science. Tools such as deep learning neural networks allow engineers and scientists to represent, simplify and interact with large collections of high dimensional (meaning many descriptors and variables) data. Neural networks and other machine learning tools allow for a type of problem-solving that reduces the amount of time spent coding and engineering the behavior of a computational system. The flexibility of these tools has led researchers to question whether or not they can be applied in creative settings. Researchers such as Robert Rowe and Morwaread Farboud have modeled the behavior of musicians with these tools and more recent attempts have been made to create consumer-facing products that generate new music at the click of a button.

Services such as Amper Music and AIVA.ai claim to provide emotive music that can be used for cinematic and promotional content. The benefit of these services being that they can be used to immediately generate music and temporary tracks for creative productions at reduced licensing and trade fees. This makes these services ideally applicable in the advertising and social media industry where turnaround time is fast and unique-sonic-identity is of lesser concern. These services prompt a user to define the type of music they would like to generate by selecting from a range of high-level descriptors that define the mood, genre, and instrumentation of a piece. This is not unlike what a film composer is prompted to do when working with a director. In film composition, it is almost common practice to help a director define the sound of their film by referencing the sound of previously popular films or asking for descriptors of mood, genre, historical period, and instrumentation. Composers train for their job by attempting to compose many of their pieces in the style of historically famous composers. Score generating services are trained on massive song lists and can arguably equate to the way a composer might work.  In both cases either a composer or a computer risk composing generic music.

Ridley Scott’s Blade Runner was in part aesthetically inspired by French noir cinema. As a result the score composer, Vangelis, incorporated jazz compositional techniques into the compositions of Blade Runner’s score. Most crucially he composed the score by improvising in direct response to what he was seeing on screen. This method of composition was made famous by Miles Davis when he scored Loius Malle’s 1958 “Ascenseur pour l’échafaud” which he is said to have scored in one sitting by improvising a trumpet line in direct response to the moving image. Davis’ trumpet playing is praised for its nuance of tone and so too is Vangelis’ score. Something that seems to be provided by their ability to emotionally interact with the visual context of each passing frame. Without too much deliberation their musical training allows these composers to innately imbue a scene with keystrokes and horn flares that so precisely fit the dramatic moments being presented.

There is a scene in Blade Runner during which the main character Deckard confronts Rachel with the knowledge that her memories are implants. He challenges her personhood in a way that upsets her. Vangelis scores this melancholic moment with emotional and lively music that still maintains a futuristic zeal through its use of synthesized sound. His score is well attuned to the demands of the moment and is crafted to suit the surrounding dialogue and sound effects. If we score the same scene with Amper Music’s service using descriptors such as “cinematic”, “ambient” and “melancholic” we obtain a score that exhibits a good overall emotional tone but that fails to react to the scene on a shot for shot basis. There is a layer of feedback missing. The music is disconnected from the visual content. This is because machine learning technologies cannot learn in real-time. They cannot adjust the models with which they are trained on a continuous time-varying basis. This limitation prevents them from generating a truly human output especially in the context of an improvised and reactive performance. 

Amper Music attempts to remedy this by allowing a user to define three hit-points along the timeline of a generated track. Here you can define whether the musical tension swells upwards, reaches a climax, or settles down for an ending. Upon adjusting the placement of these markers the effect they have on the music is not overwhelmingly apparent. The music continues without regard for the specified hit-points. This might be remedied by updating the Amper Music system to modulate its descriptors at specified hit-points allowing it to switch to new models more appropriate to specific moments of the scene. The next means of improving the system would include extracting meaningful data from the film content uploaded by the user and using frame by frame changes in the picture to update and swap out models as the film progresses. That being said it is also important to consider that this limit in the nuance of expression may be a type of planned obsolescence.

Limiting the reactivity of the models and the applicability of their product could be a type of intentional design flaw that increases the likelihood that a user might return sometime later to make use of Amper’s online service.  Without the perfect music for my scene, I might want to use Amper’s services to generate several songs to cut between. This would increase what I spend on licensing fees. It is, however, likely that the technology is just not yet capable of the type of reactivity that human performers exhibit in improvisational forms. Generating a score for Blade Runner in the same fashion as Vangelis requires the experience of learning to simultaneously listen to and improvise with other musicians; the ability to watch the visual scenery and react to it as if it were music and the creative idiosyncrasies of individual style that can only come about from having lived a human life. 
A life during which your choices of musical training and exposure aren’t as simple as “let me parse the frequency and amplitude values of every second-by-second frame of Debussy’s repertoire,” and hope that leads me to a fruitful career in impressionistic composition. Those that become composers more often do so because of chance exposure to particular styles of music within their cultural vicinity. Some facet of their imagination is captured by an ephemeral phenomenological quality that emerges from the unitive movement and arrangement of harmonic spectra amongst the players of a living ensemble. Upon recognizing this glimmer in a piece of music for the first time - either through goosebumps or momentarily foregoing all perceptions save the music of the moment - a composer might seek out training to strengthen their understanding of music and its ability to produce sensation within the mind of the willing listener.

Musical composition is at heart a type of oral tradition. It is often the case that composers will list a lineage of teachers in their resumés and concert scripts to communicate their outlooks and working methods in the process of organizing sound and to indicate a link to some bygone spiritual significance presumably passed from teacher to student. When you train on an individual basis with another composer they do their best to teach you how they pay attention to the copious amounts of sonic detail (beyond the range of just 20Hz to 20000kHZ) that fill the spaces of ordinary moments and how they rearrange those moments by reorganizing or introducing handcrafted sonic alterations using culturally and time appropriate methods. Creative work comes down to learning how to think both with and against one’s training. To open one’s cognitive filters such that new ideas can push past the gates of the default mode network. Bubbling up from unconscious sources to be filtered through the language of one’s formal training. The individual composer endures periods of experimentation and innovation within certain personal styles that eventually become formalized techniques. The same pattern repeats at the grander level of compositional schools undergoing shifts in technique through generational variance, establishment, demise, and eventual resurgence. Within the artistic practice, the importance of history’s influence and gradual processes cannot be understated.  

With the emergence of Artificial Intelligence tools in creative fields, we see the strengthening of modern trends towards the trivialization of artistic and human decision-making. An attempt by business school graduates to substitute deliberate, careful, emotionally driven design and consideration decisions with the fast-paced for-profit machinic delivery that a manically paced global content market demands. It’ll take some time and careful consideration before artificial intelligence tools can equate the emotionally driven reasoning of trained musicians. The kind of time that for-profit metrics just don’t allow for. 


##### Works Cited

* Bulow, Jeremy (November 1986). "An Economic Theory of Planned Obsolescence".
    * The Quarterly Journal of Economics. Oxford University Press. 
* Debord, Guy. Society of the Spectacle. Black and Red, 1977.
* LoBrutto, Vincent. Sound-on-Film: Interviews with Creators of Film Sound. Praeger, 1998.
* Soulsby, Nick. The Myth and Majesty of Vangelis’ Timeless Blade Runner Soundtrack. Vanity Fair. 2017.
* Brody, Richard. Louis Malle’s “Elevator to the Gallows,” and Its Historic Miles Davis Soundtrack. 2016
* Robert, Rowe. Machine Musicianship. The MIT Media Press. 2004.
